{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1317a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from pytorch_model_summary import summary\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import random\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f1fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b9b25",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e2d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_encoder = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ccff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in bert_encoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "bert_encoder.pooler.dense.weight.requires_grad = True\n",
    "bert_encoder.pooler.dense.bias.requires_grad = True\n",
    "\n",
    "# for name, param in bert_encoder.named_parameters():\n",
    "#     print(f\"{name}: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cddf09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized = tokenizer.encode_plus(\"hello my name is nate\",\n",
    "                                  max_length=20,\n",
    "                                  pad_to_max_length=True,\n",
    "                                  return_attention_mask=True,\n",
    "                                  return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    encodings = bert_encoder(**tokenized)\n",
    "    \n",
    "last_hidden_states = encodings.last_hidden_state\n",
    "bert_encodings = last_hidden_states.mean(dim=1).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f27b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 101\n",
    "EOS_token = 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abb1b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeString(text, tokenizer, encoder):\n",
    "    indexed = tokenizer.encode_plus(text,\n",
    "                                    max_length=20,\n",
    "                                    pad_to_max_length=True,\n",
    "                                    return_attention_mask=True,\n",
    "                                    return_tensors=\"pt\")\n",
    "    attention_mask = indexed[\"attention_mask\"]\n",
    "    with torch.no_grad():\n",
    "        encodings = encoder(**indexed)\n",
    "        \n",
    "    last_hidden_states = encodings.last_hidden_state\n",
    "    return last_hidden_states, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35275f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs():\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    lines = []\n",
    "    counter = 0\n",
    "\n",
    "    with open(\"/media/nathanmon/389E28739E282BB6/Users/Natha/Datasets/MyJarvisConversation/conversation.txt\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            if line[0] == \"U\":\n",
    "                lines.append(\"\")\n",
    "                lines[counter] += line[6:] + \"/t\"\n",
    "            elif line[0] == \"J\":\n",
    "                line = line.replace(\"/u\", \"/u \")\n",
    "                lines[counter] += line[8:]\n",
    "                counter += 1\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21facffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 20\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e2a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData():\n",
    "    pairs = readLangs()\n",
    "    pairs = filterPairs(pairs)\n",
    "    for i, pair in enumerate(pairs):\n",
    "        pairs[i] = pair.lower().replace(\"\\n\", \"\").split(\"/t\")\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa6f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = prepareData()\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eada4560",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"/u shopping\", \"/u todolist\", \"/u wiki\", \"/u volume\", \"/a/\"]\n",
    "filenames = [\"shopping_items\", \"todo_list_items\", \"wiki_queries\", \"volumes\", \"apps\"]\n",
    "augments = {\"shopping_items\": [], \"todo_list_items\": [],\n",
    "            \"wiki_queries\": [], \"volumes\": [], \"apps\": []}\n",
    "\n",
    "for keyword, filename in zip(keywords, filenames):\n",
    "    with open(f\"/media/nathanmon/389E28739E282BB6/Users/Natha/Datasets/MyJarvisConversation/{filename}.txt\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            augments[filename].append(line.replace(\"\\n\", \"\").strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878414cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(self, pairs, augments,\n",
    "                 batch_size=16, max_length=150):\n",
    "        self.pairs = pairs\n",
    "        self.augments = augments\n",
    "        self.batch_size = batch_size\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.numbers = [\"zero\", \"one\", \"two\", \"three\", \"four\", \n",
    "           \"five\", \"six\", \"seven\", \"eight\", \"nine\",\n",
    "           \"ten\", \"eleven\", \"twelve\", \"thirteen\",\n",
    "           \"fourteen\", \"fifteen\", \"sixteen\", \n",
    "           \"seventeen\", \"eighteen\", \"nineteen\",\n",
    "           \"twenty\", \"thirty\", \"forty\", \"fifty\",\n",
    "           \"sixty\", \"seventy\", \"eighty\", \"ninety\",\n",
    "           \"hundred\", \"thousand\", \"million\", \"billion\",\n",
    "           \"trillion\", \"quadrillion\", \"quintillion\", \"mute\", \"?\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def sentence2num(self, sentence):\n",
    "        words = sentence.split(\" \")\n",
    "        filtered = []\n",
    "        for word in words:\n",
    "            if word.lower() in self.numbers:\n",
    "                filtered.append(word)\n",
    "\n",
    "        return \" \".join(filtered)\n",
    "    \n",
    "    def find_tgt(self, response, loc=\"'\"):\n",
    "        lower = response.index(loc) + len(loc)\n",
    "        upper = response[lower:].index(loc) + lower\n",
    "        return response[lower:upper]\n",
    "    \n",
    "    def augment(self, inp, tgt):\n",
    "        keywords = [\"/u shopping\", \"/u todolist\", \"/u wiki\", \"/u volume\", \"/a\"]\n",
    "        filenames = [\"shopping_items\", \"todo_list_items\", \"wiki_queries\", \"volumes\", \"apps\"]\n",
    "\n",
    "        for keyword, filename in zip(keywords, filenames):\n",
    "            if keyword in tgt or keyword in inp:\n",
    "                if keyword == \"/u volume\":\n",
    "                    prev_item = self.sentence2num(self.find_tgt(tgt))\n",
    "                elif keyword == \"/a\":\n",
    "                    prev_item = self.find_tgt(inp, \"/a\")\n",
    "                else:\n",
    "                    prev_item = self.find_tgt(tgt)\n",
    "\n",
    "                if keyword != \"/uvolume\" or (prev_item != \"?\"and prev_item != \"Mute\"):\n",
    "                    replacement = random.choice(self.augments[filename])\n",
    "                    inp = inp.replace(prev_item, replacement)\n",
    "                    if keyword == \"/a\":\n",
    "                        prev_item = self.find_tgt(tgt)\n",
    "                    tgt = tgt.replace(prev_item, replacement)\n",
    "                    return inp.replace(\"/a\", \"\"), tgt.replace(\"/a\", \"\")\n",
    "        return inp, tgt\n",
    "\n",
    "    def getitem(self, idx, augment=False):\n",
    "        inps_tokenized, inps_types, inps_masked, targs_in, targs_out = [], [], [], [], []\n",
    "        start_idx = idx*self.batch_size\n",
    "        for (inp, tgt) in self.pairs[start_idx:start_idx+batch_size]:\n",
    "            if augment:\n",
    "                inp, tgt = self.augment(inp, tgt)\n",
    "            \n",
    "            inp_encoded = tokenizer.encode_plus(inp,\n",
    "                                                max_length=20,\n",
    "                                                pad_to_max_length=True,\n",
    "                                                return_attention_mask=True,\n",
    "                                                return_tensors=\"pt\")\n",
    "            inps_tokenized.append(inp_encoded['input_ids'][0].tolist())\n",
    "            inps_types.append(inp_encoded[\"token_type_ids\"][0].tolist())\n",
    "            inps_masked.append(inp_encoded['attention_mask'][0].tolist())\n",
    "\n",
    "            tgt_encoded = tokenizer.encode_plus(tgt,\n",
    "                                                max_length=20,\n",
    "                                                pad_to_max_length=True,\n",
    "                                                return_attention_mask=True,\n",
    "                                                return_tensors=\"pt\")\n",
    "            tgt_tokenized = tgt_encoded['input_ids'][0]\n",
    "    #         tgt_masked = tgt_encoded['attention_mask'][0]\n",
    "\n",
    "            targ_in = tgt_tokenized[:-1].tolist()\n",
    "            targ_out = tgt_tokenized[1:].tolist()\n",
    "            targs_in.append(targ_in)\n",
    "            targs_out.append(targ_out)\n",
    "            \n",
    "        inps_tokenized = torch.tensor(inps_tokenized).to(device)\n",
    "        inps_types = torch.tensor(inps_types).to(device)\n",
    "        inps_masked = torch.tensor(inps_masked).to(device)\n",
    "        targs_in = torch.tensor(targs_in).to(device)\n",
    "        targs_out = torch.tensor(targs_out).to(device)\n",
    "            \n",
    "        return inps_tokenized, inps_types, inps_masked, targs_in, targs_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2ab54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "dataloader = TokenizedDataset(pairs, augments, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a6cdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = random.choice(pairs)\n",
    "dataloader.augment(pair[0], pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33449cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcaba16",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872f4d18",
   "metadata": {},
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4575fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "    depth = depth/2\n",
    "\n",
    "    positions = torch.unsqueeze(torch.arange(length), 1)\n",
    "    depths = torch.unsqueeze(torch.arange(depth), 0)/depth\n",
    "#     positions = torch.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "#     depths = torch.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "    angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "    angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "    pos_encoding = torch.cat(\n",
    "      [torch.sin(angle_rads), torch.cos(angle_rads)],\n",
    "      axis=-1) \n",
    "\n",
    "    return pos_encoding.to(device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f3d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=0)\n",
    "        # The positional encoding is used to introduce sequence to a sentence by causing words near \n",
    "        # eachother to have similar vectors\n",
    "        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "    def compute_mask(self, *args, **kwargs):\n",
    "        return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        length = np.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "        x *= math.sqrt(torch.tensor(self.d_model).type(torch.float32))\n",
    "        x = x + torch.unsqueeze(self.pos_encoding, 0)[:, :length]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f677df5d",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b80176",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(nn.Module):\n",
    "    def __init__(self, d_model, **kwargs):\n",
    "        super().__init__()\n",
    "        self.num_heads = kwargs.get('num_heads')\n",
    "        self.mha = nn.MultiheadAttention(**kwargs)\n",
    "        self.layernorm = nn.LayerNorm(d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e4d8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(BaseAttention):\n",
    "    def forward(self, x, context):\n",
    "        x_ = x.permute(1, 0, 2)\n",
    "        context_ = context.permute(1, 0, 2)\n",
    "        attn_output, attn_scores = self.mha(\n",
    "            query=x_,\n",
    "            key=context_,\n",
    "            value=context_,\n",
    "            need_weights=True)\n",
    "        attn_output = attn_output.permute(1, 0, 2)\n",
    "        attn_scores = attn_scores.permute(1, 0, 2)\n",
    "\n",
    "        # Cache the attention scores for plotting later.\n",
    "        self.last_attn_scores = attn_scores\n",
    "\n",
    "        x =x + attn_output\n",
    "        x = self.layernorm(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "sample_ca = CrossAttention(d_model=256, embed_dim=128, num_heads=2, kdim=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ead0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(BaseAttention):\n",
    "    def forward(self, x):\n",
    "        x_ = x.permute(1, 0, 2)\n",
    "        attention_mask = nn.Transformer.generate_square_subsequent_mask(x_.shape[0]).to(device)\n",
    "        attention_mask = attention_mask.expand(x_.shape[1]*self.num_heads, -1, -1).to(device)\n",
    "        \n",
    "        attn_output = self.mha(\n",
    "            query=x_,\n",
    "            value=x_,\n",
    "            key=x_,\n",
    "            attn_mask=attention_mask,\n",
    "            is_causal=True)[0]\n",
    "        attn_output = attn_output.permute(1, 0, 2)\n",
    "        x = x + attn_output\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "    \n",
    "sample_csa = CausalSelfAttention(d_model=256, embed_dim=128, \n",
    "                                 num_heads=2, kdim=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4ae535",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e864b861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(d_model, dff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dff, d_model),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        ).to(device)\n",
    "        self.layer_norm = nn.LayerNorm(d_model).to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.seq(x)\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "    \n",
    "sample_ffn = FeedForward(28, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db90932",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, *, emb_size, d_model, dff,\n",
    "                   dropout_rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.bert_encoder = bert_encoder\n",
    "        \n",
    "        self.ffn = FeedForward(emb_size, dff)\n",
    "        self.linear = nn.Linear(emb_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_tensor, input_type, input_mask = x\n",
    "        x = self.bert_encoder(input_tensor, input_type, input_mask).last_hidden_state\n",
    "        x = self.ffn(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1e4092",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaacb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                   *,\n",
    "                   d_model,\n",
    "                   num_heads,\n",
    "                   dff,\n",
    "                   dropout_rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.causal_self_attention = CausalSelfAttention(\n",
    "            d_model=d_model,\n",
    "            embed_dim=d_model,\n",
    "            num_heads=num_heads,\n",
    "            kdim=d_model,\n",
    "            dropout=dropout_rate).to(device)\n",
    "        \n",
    "        self.cross_attention = CrossAttention(\n",
    "            d_model=d_model,\n",
    "            embed_dim=d_model,\n",
    "            num_heads=num_heads,\n",
    "            kdim=d_model,\n",
    "            dropout=dropout_rate).to(device)\n",
    "\n",
    "        self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "    def forward(self, x, context):\n",
    "        x = self.causal_self_attention(x=x)\n",
    "        x = self.cross_attention(x=x, context=context)\n",
    "\n",
    "        # Cache the last attention scores for plotting later\n",
    "        self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "        x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92047b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, *, emb_size, num_layers, d_model, num_heads, dff, vocab_size,\n",
    "                   dropout_rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.linear = nn.Linear(emb_size, d_model)\n",
    "        self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
    "                                                 d_model=d_model).to(\"cuda\")\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.dec_layers = [\n",
    "            DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
    "                         dff=dff, dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)]\n",
    "        self.dec_layers = nn.ModuleList(self.dec_layers)\n",
    "\n",
    "        self.last_attn_scores = None\n",
    "        \n",
    "        self.final_layer = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x, context):\n",
    "        x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x  = self.dec_layers[i](x, context)\n",
    "\n",
    "        self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "        logits = self.final_layer(x)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a36fe82",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a3648",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, *, bert_encoder, emb_size, num_layers, d_model, num_heads, \n",
    "                 dff, vocab_size, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(emb_size=emb_size, d_model=d_model, dff=dff, dropout_rate=dropout_rate)\n",
    "        self.decoder = Decoder(emb_size=emb_size, num_layers=num_layers, d_model=d_model,\n",
    "                               num_heads=num_heads, dff=dff, vocab_size=vocab_size,\n",
    "                               dropout_rate=dropout_rate)\n",
    "\n",
    "        self.final_layer = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input_tensor, input_type, input_mask, x = input\n",
    "        context = self.encoder((input_tensor,\n",
    "                               input_type,\n",
    "                               input_mask)) # (batch_size, target_len, 768)\n",
    "        \n",
    "        x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
    "\n",
    "\n",
    "        # Return the final output and the attention weights.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29449f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del transformer\n",
    "except:\n",
    "    pass\n",
    "\n",
    "num_layers = 5\n",
    "emb_size = 768\n",
    "d_model = 1024\n",
    "dff = 2056\n",
    "num_heads = 16\n",
    "dropout_rate = 0.7\n",
    "\n",
    "# transformer = Transformer(\n",
    "#     bert_encoder=bert_encoder,\n",
    "#     emb_size=emb_size,\n",
    "#     num_layers=num_layers,\n",
    "#     d_model=d_model,\n",
    "#     num_heads=num_heads,\n",
    "#     dff=dff,\n",
    "#     vocab_size=len(tokenizer.get_vocab()),\n",
    "#     dropout_rate=dropout_rate).to(device)\n",
    "\n",
    "encoder = Encoder(emb_size=emb_size, d_model=d_model, dff=dff, dropout_rate=dropout_rate).to(device)\n",
    "decoder = Decoder(emb_size=emb_size, num_layers=num_layers, d_model=d_model,\n",
    "                               num_heads=num_heads, dff=dff, vocab_size=len(tokenizer.get_vocab()),\n",
    "                               dropout_rate=dropout_rate).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d1e286",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_plus(\"hello there\",\n",
    "                                  max_length=20,\n",
    "                                  pad_to_max_length=True,\n",
    "                                  return_attention_mask=True,\n",
    "                                  return_tensors=\"pt\").to(device)\n",
    "tokenized = encoding[\"input_ids\"]\n",
    "types = encoding[\"token_type_ids\"]\n",
    "mask = encoding[\"attention_mask\"]\n",
    "context = encoder((tokenized, types, mask))\n",
    "\n",
    "print(summary(encoder, (tokenized, types, mask), show_input=True))\n",
    "print(summary(decoder, torch.zeros((1, 20), dtype=torch.int32).to(device), context, show_input=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaae970",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c880eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "    mask = label != 0\n",
    "\n",
    "    loss_object = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    \n",
    "    pred_flat = pred.view(-1, pred.size(-1))\n",
    "    label_flat = label.view(-1)\n",
    "    \n",
    "    pred_masked = pred_flat[mask.view(-1)]\n",
    "    label_masked = label_flat[mask.view(-1)]\n",
    "    \n",
    "    loss = loss_object(pred_masked, label_masked)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "    pred = torch.argmax(pred, axis=2)\n",
    "    label = label.to(pred.dtype)\n",
    "    match = label == pred\n",
    "\n",
    "    mask = label != 0\n",
    "\n",
    "    match = match & mask\n",
    "\n",
    "    match = match.to(torch.float32)\n",
    "    mask = mask.to(torch.float32)\n",
    "    return torch.sum(match)/torch.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7cc4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, \n",
    "                decoder_optimizer, criterion, augment, train=True):\n",
    "    global batch_size\n",
    "    total_loss = 0\n",
    "    for batch in range(len(dataloader) // batch_size):\n",
    "        input_tensor, input_type, input_mask, tensor_in, tensor_out = dataloader.getitem(batch, augment)\n",
    "        inputs = (input_tensor, input_type,\n",
    "                  input_mask, tensor_in)\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        if decoder_optimizer is not None:\n",
    "            decoder_optimizer.zero_grad()\n",
    "        \n",
    "        if decoder is not None:\n",
    "            context = encoder((input_tensor,\n",
    "                               input_type,\n",
    "                               input_mask))\n",
    "            logits = decoder(tensor_in, context)\n",
    "        else:\n",
    "            logits = encoder(inputs)\n",
    "        loss = masked_loss(tensor_out, logits)\n",
    "        \n",
    "        if train:\n",
    "            loss.backward()\n",
    "\n",
    "            encoder_optimizer.step()\n",
    "            if decoder_optimizer is not None:\n",
    "                decoder_optimizer.step()\n",
    "    \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / (len(dataloader) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb9672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b709aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveBestModel:\n",
    "    \"\"\"\n",
    "    Class to save the best model while training. If the current epoch's \n",
    "    validation loss is less than the previous least less, then save the\n",
    "    model state.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, best_valid_loss=float('inf')\n",
    "    ):\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        \n",
    "    def __call__(\n",
    "        self, current_valid_loss, \n",
    "        epoch, encoder, decoder,\n",
    "        encoder_optimizer, decoder_optimizer, criterion\n",
    "    ):\n",
    "        if current_valid_loss < self.best_valid_loss:\n",
    "            self.best_valid_loss = current_valid_loss\n",
    "            print(f\"Best validation loss: {self.best_valid_loss}\")\n",
    "            print(f\"Saving best model for epoch: {epoch+1}\")\n",
    "            torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model_state_dict': encoder.state_dict(),\n",
    "                'optimizer_state_dict': encoder_optimizer.state_dict(),\n",
    "                'loss': criterion,\n",
    "                }, 'checkpoints/best_encoder.pth')\n",
    "            if decoder is not None:\n",
    "                torch.save({\n",
    "                    'epoch': epoch+1,\n",
    "                    'model_state_dict': decoder.state_dict(),\n",
    "                    'optimizer_state_dict': decoder_optimizer.state_dict(),\n",
    "                    'loss': criterion,\n",
    "                    }, 'checkpoints/best_decoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38685547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(train_dataloader, val_dataloader, transformer, n_epochs, learning_rate=0.001,\n",
    "def train(train_dataloader, val_dataloader, encoder, decoder, n_epochs, augment=True,\n",
    "          encoder_lr=1e-3, decoder_lr=1e-3, print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    global d_model\n",
    "    print_train_loss_total = 0  # Reset every print_every\n",
    "    plot_train_loss_total = 0  # Reset every plot_every\n",
    "    plot_train_losses = []\n",
    "    \n",
    "    plot_encoder_lrs = []\n",
    "    plot_decoder_lrs = []\n",
    "    \n",
    "    plot_val_loss_total = 0\n",
    "    plot_val_losses = []\n",
    "    print_val_loss_total = 0  # Reset every print_every\n",
    "\n",
    "    save_best = SaveBestModel(best_valid_loss=.59)\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=encoder_lr,\n",
    "                                   betas=(0.95, 0.9995), eps=1e-9)\n",
    "    encoder_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, \"min\", factor=0.05, patience=250)\n",
    "    decoder_optimizer = None\n",
    "    decoder_scheduler = None    \n",
    "    if decoder is not None:\n",
    "        decoder_optimizer = optim.Adam(decoder.parameters(), lr=decoder_lr,\n",
    "                                       betas=(0.95, 0.9995), eps=1e-9)\n",
    "        decoder_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(decoder_optimizer, \"min\", factor=0.05, patience=250)\n",
    "        \n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "#         train_loss = train_epoch(train_dataloader, transformer, optimizer, scheduler, criterion, augment)\n",
    "        train_loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, \n",
    "                                 decoder_optimizer, criterion, augment)\n",
    "        print_train_loss_total += train_loss\n",
    "        plot_train_loss_total += train_loss\n",
    "        \n",
    "        # Evaluate validation dataloader\n",
    "#         val_loss = train_epoch(val_dataloader, transformer, optimizer, scheduler, criterion, augment, train=False)\n",
    "        val_loss = train_epoch(val_dataloader, encoder, decoder, encoder_optimizer,\n",
    "                               decoder_optimizer, criterion, augment, train=False)\n",
    "        print_val_loss_total += val_loss\n",
    "        plot_val_loss_total += val_loss\n",
    "        \n",
    "        save_best(val_loss, epoch, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        \n",
    "        encoder_scheduler.step(val_loss)\n",
    "        if decoder_scheduler is not None:\n",
    "            decoder_scheduler.step(val_loss)\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_train_loss_avg = print_train_loss_total / print_every\n",
    "            print_train_loss_total = 0\n",
    "            print_val_loss_avg = print_val_loss_total / print_every\n",
    "            print_val_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f %.4f %.7f %.7f' % (timeSince(start, epoch / n_epochs),\n",
    "                epoch, epoch / n_epochs * 100, print_train_loss_avg, print_val_loss_avg,\n",
    "                encoder_optimizer.param_groups[0][\"lr\"],\n",
    "                decoder_optimizer.param_groups[0][\"lr\"] if decoder_optimizer is not None else encoder_optimizer.param_groups[0][\"lr\"]))\n",
    "            plot_encoder_lrs.append(encoder_optimizer.param_groups[0][\"lr\"])\n",
    "            if decoder is not None:\n",
    "                plot_decoder_lrs.append(decoder_optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_train_loss_avg = plot_train_loss_total / plot_every\n",
    "            plot_train_losses.append(plot_train_loss_avg)\n",
    "\n",
    "            plot_train_loss_total = 0\n",
    "            \n",
    "            plot_val_loss_avg = plot_val_loss_total / plot_every\n",
    "            plot_val_losses.append(plot_val_loss_avg)\n",
    "\n",
    "            plot_val_loss_total = 0\n",
    "\n",
    "    showPlot(plot_train_losses, \"loss\", plot_val_losses, \"val_loss\")\n",
    "    if decoder is None:\n",
    "        showPlot(plot_encoder_lrs, \"encoder learning rate\")\n",
    "    else:\n",
    "        showPlot(plot_encoder_lrs, \"encoder learning_rate\", plot_decoder_lrs, \"decoder learning rate\")\n",
    "    return plot_train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2006fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points, points_name, points2=None, points2_name=None):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.5)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    if points2 != None:\n",
    "        plt.plot(np.arange(len(points)), points, points2)\n",
    "        plt.legend([points_name, points2_name])\n",
    "    else:\n",
    "        plt.plot(points)\n",
    "        plt.legend([points_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ef9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bbad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0f5570",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataloader = TokenizedDataset(pairs[:210], augments, \n",
    "                                   batch_size=batch_size)\n",
    "val_dataloader = TokenizedDataset(pairs[210:], augments, \n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "history = train(train_dataloader, val_dataloader, encoder, decoder, 3000, encoder_lr=1e-5, decoder_lr=1e-4, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7c14df",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_ckpt, decoder_ckpt = torch.load(\"checkpoints/best_encoder.pth\"), torch.load(\"checkpoints/best_decoder.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92963897",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_state_dict(encoder_ckpt['model_state_dict'])\n",
    "decoder.load_state_dict(decoder_ckpt['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95f2c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentenceFromIndexes(encoded):\n",
    "    words = []\n",
    "    for word in encoded:\n",
    "        words.append(list(tokenizer.get_vocab().keys())[word])\n",
    "        \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce97819",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot():\n",
    "    def __init__(self, encoder, decoder):\n",
    "#         self.transformer = transformer\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def __call__(self, sentence):\n",
    "        inp_encoded = tokenizer.encode_plus(sentence,\n",
    "                                            max_length=20,\n",
    "                                            pad_to_max_length=True,\n",
    "                                            return_attention_mask=True,\n",
    "                                            return_tensors=\"pt\")\n",
    "        inp_tokenized = inp_encoded['input_ids']\n",
    "        inp_types = inp_encoded[\"token_type_ids\"]\n",
    "        inp_masked = inp_encoded['attention_mask']\n",
    "        \n",
    "        encoder_input = sentence\n",
    "\n",
    "        output_array = torch.tensor([[SOS_token]]) # tokens, batch size\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(MAX_LENGTH):\n",
    "                output = output_array.transpose(0, 1) # batch size, tokens\n",
    "#                 predictions = self.transformer((inp_tokenized.to(device),\n",
    "#                                                 inp_types.to(device),\n",
    "#                                                 inp_masked.to(device),\n",
    "#                                                 output.to(device))) # batch size, tokens, vocab size\n",
    "                context = encoder((inp_tokenized.to(device),\n",
    "                   inp_types.to(device),\n",
    "                   inp_masked.to(device)))\n",
    "                predictions = decoder(output.to(device), context)\n",
    "                \n",
    "                predictions = predictions[:, -1:, :] # batch_size, 1, vocab_size\n",
    "                \n",
    "                predicted_id = torch.argmax(predictions, -1)\n",
    "                \n",
    "                output_array = torch.cat((output_array.to(device),\n",
    "                                          predicted_id), 0)\n",
    "                \n",
    "                if predicted_id[0] == torch.tensor([EOS_token]).to(device):\n",
    "                    break\n",
    "\n",
    "        output = torch.unsqueeze(torch.flatten(output_array), 0)\n",
    "        \n",
    "        tokens = sentenceFromIndexes(output[0].tolist())\n",
    "        text = ' '.join(tokens)\n",
    "\n",
    "        with torch.no_grad():\n",
    "#             self.transformer((inp_tokenized.to(device),\n",
    "#                               inp_types.to(device),\n",
    "#                               inp_masked.to(device),\n",
    "#                               output[:,:-1].to(device)))\n",
    "            context = encoder((inp_tokenized.to(device),\n",
    "                               inp_types.to(device),\n",
    "                               inp_masked.to(device)))\n",
    "            predictions = decoder(output.to(device), context)\n",
    "            attention_weights = self.decoder.last_attn_scores\n",
    "\n",
    "        return text, attention_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99bac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatbot = Chatbot(transformer)\n",
    "chatbot = Chatbot(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c65cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_translation(sentence, tokens):\n",
    "    print(f'{\"Input:\":15s}: {sentence}')\n",
    "    print(f'\\n{\"Prediction\":15s}: {tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0e3adf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sentence = \"What is the temperature today\"\n",
    "\n",
    "translated_text, attention_weights = chatbot(sentence)\n",
    "print_translation(sentence, translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28af774",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
