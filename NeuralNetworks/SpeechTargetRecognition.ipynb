{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be54a703",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137d1972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch import Tensor\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d828182",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719a56b5",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d29fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spoken_to = [\"Hey Jarvis, what's the weather today\",\n",
    "             \"What time is it\",\n",
    "             \"Where are we Jarvis\",\n",
    "             \"Set a three minute timer\",\n",
    "             \"Jarvis, what's the weather like today?\",\n",
    "             \"Can you set a reminder for 3 PM, Jarvis?\",\n",
    "             \"Hey Jarvis, play my favorite song.\",\n",
    "             \"Jarvis, how do you define artificial intelligence?\",\n",
    "             \"What's on my schedule for tomorrow, Jarvis?\",\n",
    "             \"Tell me, what's the weather like today?\",\n",
    "             \"Remind me to buy groceries at 5 PM.\",\n",
    "             \"Play my favorite song now.\",\n",
    "             \"Can you define artificial intelligence?\",\n",
    "             \"What's on my schedule for tomorrow?\",\n",
    "             \"Set a timer for 10 minutes.\",\n",
    "             \"What's the weather forecast for tomorrow?\",\n",
    "             \"Open Google and search for recent news.\",\n",
    "             \"Play my favorite playlist on Spotify.\",\n",
    "             \"Turn off the lights in the living room.\",\n",
    "             \"Send a text message to John saying I'll be there in 10 minutes.\",\n",
    "             \"Define the word 'serendipity.'\",\n",
    "             \"Tell me a joke.\",\n",
    "             \"What's the capital of France?\",\n",
    "             \"Read me the latest email Jarvis.\",\n",
    "             \"What's on my calendar for today?\",\n",
    "             \"Hey Jarvis, convert 100 dollars to euros.\",\n",
    "             \"Find a recipe for chicken Alfredo.\",\n",
    "             \"Translate 'hello' to Spanish.\",\n",
    "             \"What's the population of Tokyo?\",\n",
    "             \"Remind me to buy groceries at 5 PM.\",\n",
    "             \"Open the camera and take a photo.\",\n",
    "             \"What's the latest stock price for Apple?\",\n",
    "             \"Set an alarm for 7 AM tomorrow.\",\n",
    "             \"Navigate to the nearest gas station.\",\n",
    "             \"Hey Jarvis, set a timer for 15 minutes.\",\n",
    "             \"Can you check my email, Jarvis?\",\n",
    "             \"Hey, what's the weather like today?\",\n",
    "             \"Jarvis, play some relaxing music, please.\",\n",
    "             \"Could you remind me to call mom later, Jarvis?\",\n",
    "             \"Hey Jarvis, turn on the lights in the living room.\",\n",
    "             \"Can you find a good recipe for chocolate chip cookies, Jarvis?\",\n",
    "             \"Jarvis, tell me a joke to lighten the mood.\",\n",
    "             \"Hey, Jarvis, read me the latest news headlines.\",\n",
    "             \"Could you add 'buy birthday gift' to my to-do list, Jarvis?\",\n",
    "             \"Jarvis, what's on my calendar for the day?\",\n",
    "             \"Hey Jarvis, find directions to the nearest coffee shop.\",\n",
    "             \"Can you set an appointment for me at 2 PM, Jarvis?\",\n",
    "             \"Hey, Jarvis, check the stock prices for my portfolio.\",\n",
    "             \"Jarvis, translate 'hello' to French for me.\",\n",
    "             \"Could you open the camera and take a picture, Jarvis?\",\n",
    "             \"Hey Jarvis, what's the population of New York City?\",\n",
    "             \"Jarvis, could you order a pizza for delivery?\",\n",
    "             \"Can you tell me a fun fact, Jarvis?\",\n",
    "             \"Hey, Jarvis, send a text to Sarah that I'll be there soon.\",\n",
    "             \"What's on my calendar for tomorrow?\",\n",
    "             \"Find directions to the nearest gas station.\",\n",
    "             \"Set a meeting for 3 PM tomorrow.\",\n",
    "             \"Check stock prices for my favorite companies.\",\n",
    "             \"Translate 'thank you' to Spanish for me.\",\n",
    "             \"Open the camera and take a quick photo.\",\n",
    "             \"What's the population of Tokyo?\",\n",
    "             \"Order a large pepperoni pizza for delivery.\",\n",
    "             \"Tell me an interesting fact.\",\n",
    "             \"Send a text to Mark that I'll be there in 10 minutes.\",\n",
    "             \"I think our work here is done\"]\n",
    "not_spoken_to = [\"How was your day?\",\n",
    "                 \"I missed you!\",\n",
    "                 \"What's new in your life?\",\n",
    "                 \"Let's catch up soon.\",\n",
    "                 \"I appreciate your support.\",\n",
    "                 \"Can you keep a secret?\",\n",
    "                 \"I love you.\",\n",
    "                 \"How are the kids doing?\",\n",
    "                 \"You mean a lot to me.\",\n",
    "                 \"Remember that time we...\",\n",
    "                 \"I need someone to talk to.\",\n",
    "                 \"What's your favorite movie/book?\",\n",
    "                 \"I trust you with this information.\",\n",
    "                 \"You're always there for me.\",\n",
    "                 \"Let's plan something together.\",\n",
    "                 \"I value our friendship.\",\n",
    "                 \"I'm feeling a bit down today.\",\n",
    "                 \"Can you give me advice on...\",\n",
    "                 \"Thanks for being understanding.\",\n",
    "                 \"I'm here for you, no matter what.\",\n",
    "                 \"What is for dinner\",\n",
    "                 \"When is lunch going to be done\",\n",
    "                 \"Can you help me move this heavy, furniture?\",\n",
    "                 \"I need a hug right now.\",\n",
    "                 \"Let's go grab a coffee together.\",\n",
    "                 \"Can you pick up groceries on your way home?\",\n",
    "                 \"What's your favorite type of cuisine?\",\n",
    "                 \"I have a surprise for you!\",\n",
    "                 \"Let's plan a surprise party for John.\",\n",
    "                 \"What do you think about the latest fashion trends?\",\n",
    "                 \"I need your opinion on this painting I'm working on.\",\n",
    "                 \"Can you water the plants for me?\",\n",
    "                 \"Let's go for a run together.\",\n",
    "                 \"I have a secret, but I can't tell you.\",\n",
    "                 \"What's your favorite childhood memory?\",\n",
    "                 \"Can you make a decision for me?\",\n",
    "                 \"I need relationship advice.\",\n",
    "                 \"Let's go on a spontaneous road trip.\",\n",
    "                 \"What's your dream job?\",\n",
    "                 \"I have a crush on someone; what should I do?\",\n",
    "                 \"Can you babysit my kids this weekend?\",\n",
    "                 \"I have a feeling something big is going to happen.\",\n",
    "                 \"Has anyone seen my phone? I can't find it.\",\n",
    "                 \"Is someone using the TV right now? I wanted to watch something.\",\n",
    "                 \"I left my keys on the kitchen counter. Have you seen them?\",\n",
    "                 \"Did anyone finish the last of the milk? I was planning to use it.\",\n",
    "                 \"I'll be in my room if anyone needs me.\",\n",
    "                 \"Could you let me know if you're planning to use the car later?\",\n",
    "                 \"I'm going to the store; does anyone need anything?\",\n",
    "                 \"Who was the last one to use the computer in the study?\",\n",
    "                 \"I'm having friends over tonight. Is that okay with everyone?\",\n",
    "                 \"Have you seen the charger for my laptop around here?\",\n",
    "                 \"I think I left my umbrella in the living room. Can you check?\",\n",
    "                 \"Is it my turn to take out the trash, or did someone already do it?\",\n",
    "                 \"I'm planning to do laundry later. Any objections or preferences?\",\n",
    "                 \"Does anyone want the last slice of pizza in the fridge?\",\n",
    "                 \"I'm done using the bathroom; it's all yours.\",\n",
    "                 \"I'm taking a nap; please keep the noise down if possible.\",\n",
    "                 \"I'll be working in the home office for the next few hours.\",\n",
    "                 \"Has anyone seen the remote control? I can't find it anywhere.\",\n",
    "                 \"I'm on a call; please don't interrupt unless it's urgent.\",\n",
    "                 \"I made some coffee. Help yourselves if you want some.\",\n",
    "                 \"Mom, when are we leaving for school\",\n",
    "                 \"Where were you Scott\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc21c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_labels = torch.zeros(len(not_spoken_to))\n",
    "positive_labels = torch.ones(len(spoken_to))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbab122",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = np.concatenate((not_spoken_to, spoken_to))\n",
    "labels = np.concatenate((negative_labels, positive_labels))\n",
    "\n",
    "combined = list(zip(sentences, labels))\n",
    "for i in range(5):\n",
    "    np.random.shuffle(combined)\n",
    "    \n",
    "sentences, labels = zip(*combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3f2a26",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f446c03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b92fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "encoder = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd1c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b4cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer.encode_plus(\"hello my name is nate\",\n",
    "                             max_length=20,\n",
    "                             pad_to_max_length=True,\n",
    "                             return_attention_mask=True,\n",
    "                              return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    encodings = encoder(**tokenized)\n",
    "    \n",
    "last_hidden_states = encodings.last_hidden_state\n",
    "bert_encodings = last_hidden_states.mean(dim=1).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1475c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0878955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeString(text, tokenizer, encoder):\n",
    "    indexed = tokenizer.encode_plus(text,\n",
    "                                    max_length=20,\n",
    "                                    pad_to_max_length=True,\n",
    "                                    return_attention_mask=True,\n",
    "                                    return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encodings = encoder(**indexed)\n",
    "        \n",
    "    last_hidden_states = encodings.last_hidden_state\n",
    "    return last_hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ce2191",
   "metadata": {},
   "source": [
    "### Store words into tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2253de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, sentences, labels, \n",
    "                 tokenizer, encoder,\n",
    "                 batch_size=16, max_length=150):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.encoder = encoder\n",
    "        self.batch_size = batch_size\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def getitem(self, idx):\n",
    "        encodings, labels = [], []\n",
    "        start_idx = idx*self.batch_size\n",
    "        for sentence, label in zip(self.sentences[start_idx:start_idx+batch_size],\n",
    "                                   self.labels[start_idx:start_idx+batch_size]):\n",
    "            encoding = encodeString(sentence[0], self.tokenizer, self.encoder)\n",
    "            \n",
    "            encodings.append(encoding)\n",
    "            labels.append(label)\n",
    "\n",
    "        encodings = torch.cat(encodings, dim=0)\n",
    "        labels = torch.tensor(labels)\n",
    "        return encodings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d47541",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "dataloader = SentenceDataset(inputs, labels, tokenizer, encoder, batch_size=batch_size, max_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f551f05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader.getitem(0)[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aee1786",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataloader.getitem(0)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d22919",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe37260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "    \n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d91fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size, vocab_size, emb_size, num_layers, dropout_p=0.1):\n",
    "        super(TargetClassifier, self).__init__()\n",
    "#         self.positional_encoding = PositionalEncoding(emb_size, dropout_p)\n",
    "        self.gru_layers = nn.ModuleList([nn.GRU(emb_size if i == 0 else hidden_size,\n",
    "                                       hidden_size,\n",
    "                                       batch_first=True)\n",
    "                                       for i in range(num_layers)])\n",
    "        self.dense = nn.Linear(hidden_size, hidden_size)\n",
    "        self.layernorm = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.out = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "#         embedded = self.positional_encoding(x)\n",
    "    \n",
    "        for gru_layer in self.gru_layers:\n",
    "            x, _ = gru_layer(x)\n",
    "            \n",
    "        x = x[:, -1, :]\n",
    "        x = self.dense(x)\n",
    "        x = self.dropout(F.gelu(self.layernorm(x)))\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334d190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TargetClassifier(hidden_size=32,\n",
    "                         vocab_size=len(lang.word2index),\n",
    "                         emb_size=768,\n",
    "                         num_layers=1,\n",
    "                         dropout_p=0.1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a04091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, optimizer, criterion, accuracy, train=True):\n",
    "    global batch_size\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    for batch in range(len(dataloader) // batch_size):\n",
    "        sentences, labels = dataloader.getitem(batch)\n",
    "        labels = labels.unsqueeze(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(sentences)\n",
    "        loss = criterion(logits.to(torch.double), labels.to(torch.double).to(device))\n",
    "        logits = F.sigmoid(logits)\n",
    "        logits = torch.round(logits)\n",
    "        acc = accuracy(logits, labels)\n",
    "        \n",
    "        if train:\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "    \n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc\n",
    "\n",
    "    return total_loss / len(dataloader), total_acc / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de2db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_losses = []\n",
    "plot_val_losses = []\n",
    "\n",
    "def train(train_dataloader, val_dataloader, model, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    global plot_train_losses\n",
    "    global plot_val_losses\n",
    "    global d_model\n",
    "    print_train_loss_total = 0  # Reset every print_every\n",
    "    plot_train_loss_total = 0  # Reset every plot_every\n",
    "    print_train_acc_total = 0\n",
    "    \n",
    "    print_val_loss_total = 0  # Reset every print_every\n",
    "    plot_val_loss_total = 0\n",
    "    print_val_acc_total = 0\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    accuracy = lambda y_pred, target: torch.sum(y_pred == target.to(device))\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                                optimizer, mode='min',\n",
    "                                factor=0.50, patience=6)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_loss, train_acc = train_epoch(train_dataloader, model, optimizer, criterion, accuracy)\n",
    "        print_train_loss_total += train_loss\n",
    "        plot_train_loss_total += train_loss\n",
    "        print_train_acc_total += train_acc\n",
    "        \n",
    "        # Evaluate validation dataloader\n",
    "        val_loss, val_acc = train_epoch(val_dataloader, model, optimizer, criterion, accuracy, train=False)\n",
    "        print_val_loss_total += val_loss\n",
    "        plot_val_loss_total += val_loss\n",
    "        print_val_acc_total += val_acc\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_train_loss_avg = print_train_loss_total / print_every\n",
    "            print_train_acc_avg = print_train_acc_total / print_every\n",
    "            print_train_loss_total = 0\n",
    "            print_train_acc_total = 0\n",
    "            print_val_loss_avg = print_val_loss_total / print_every\n",
    "            print_val_acc_avg = print_val_acc_total / print_every\n",
    "            print_val_loss_total = 0\n",
    "            print_val_acc_total = 0\n",
    "            print('%s (%d %d%%) %.4f %.4f %.4f %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_train_loss_avg, print_val_loss_avg,\n",
    "                                        print_train_acc_avg, print_val_acc_avg))\n",
    "            print()\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_train_loss_avg = plot_train_loss_total / plot_every\n",
    "            plot_train_losses.append(plot_train_loss_avg)\n",
    "            plot_train_loss_total = 0\n",
    "            \n",
    "            plot_val_loss_avg = plot_val_loss_total / plot_every\n",
    "            plot_val_losses.append(plot_val_loss_avg)\n",
    "            plot_val_loss_total = 0\n",
    "\n",
    "    showPlot(plot_train_losses)\n",
    "    showPlot(plot_val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131ce8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed20e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader.getitem(0)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d452caf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_dataloader = SentenceDataset(inputs[:90], labels[:90], tokenizer, encoder,\n",
    "                                   batch_size=batch_size, max_length=20)\n",
    "val_dataloader = SentenceDataset(inputs[90:], labels[90:], tokenizer, encoder,\n",
    "                                 batch_size=batch_size, max_length=20)\n",
    "\n",
    "train(train_dataloader, val_dataloader, model, 15, \n",
    "      learning_rate=1e-2, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879ff35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"target_recognition.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c14da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"humidity\"\n",
    "x = encodeString(sentence, tokenizer, encoder)\n",
    "\n",
    "out = model(x)\n",
    "out = F.sigmoid(out)\n",
    "if torch.round(out) == 1:\n",
    "    print(\"Addressing Jarvis\")\n",
    "else:\n",
    "    print(\"Not addressing Jarvis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
