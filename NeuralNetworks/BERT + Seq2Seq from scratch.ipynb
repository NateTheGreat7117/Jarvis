{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f1317a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 19:28:50.876784: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-18 19:28:51.388604: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from pytorch_model_summary import summary\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import random\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "178f1fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b9b25",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117e2d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_encoder = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4cddf09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/nathanmon/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenized = tokenizer.encode_plus(\"hello my name is nate\",\n",
    "                                  max_length=20,\n",
    "                                  pad_to_max_length=True,\n",
    "                                  return_attention_mask=True,\n",
    "                                  return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    encodings = bert_encoder(**tokenized)\n",
    "    \n",
    "last_hidden_states = encodings.last_hidden_state\n",
    "bert_encodings = last_hidden_states.mean(dim=1).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "427fdb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 1013, 1057, 3872, 1005, 2702, 1005, 102]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"/u Volume'ten'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b593bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 7592, 2026, 2171, 2003, 8253,  102,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f27b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 101\n",
    "EOS_token = 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ffcd2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_encoder.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a579a408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 7592, 2026, 2171, 2003, 8253,  102,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5edbaba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1abb1b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeString(text, tokenizer, encoder):\n",
    "    indexed = tokenizer.encode_plus(text,\n",
    "                                    max_length=20,\n",
    "                                    pad_to_max_length=True,\n",
    "                                    return_attention_mask=True,\n",
    "                                    return_tensors=\"pt\")\n",
    "    attention_mask = indexed[\"attention_mask\"]\n",
    "    with torch.no_grad():\n",
    "        encodings = encoder(**indexed)\n",
    "        \n",
    "    last_hidden_states = encodings.last_hidden_state\n",
    "    return last_hidden_states, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a140e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: Set the volume to eight\n",
      "Augmented Sentence: Set the volume to eighter_from_Decatur\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random\n",
    "\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.append(lemma.name())\n",
    "    return list(set(synonyms))\n",
    "\n",
    "def synonym_replacement(sentence, num_replacements=1):\n",
    "    words = word_tokenize(sentence)\n",
    "    \n",
    "    for i in range(len(words)):\n",
    "        if random.random() < num_replacements / len(words):\n",
    "            synonyms = get_synonyms(words[i])\n",
    "            if synonyms:\n",
    "                words[i] = random.choice(synonyms)\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Example usage:\n",
    "original_sentence = \"Set the volume to eight\"\n",
    "augmented_sentence = synonym_replacement(original_sentence, num_replacements=2)\n",
    "print(\"Original Sentence:\", original_sentence)\n",
    "print(\"Augmented Sentence:\", augmented_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35275f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs():\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    lines = []\n",
    "    counter = 0\n",
    "\n",
    "    with open(\"/media/nathanmon/389E28739E282BB6/Users/Natha/Datasets/MyJarvisConversation/conversation.txt\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            if line[0] == \"U\":\n",
    "                lines.append(\"\")\n",
    "                lines[counter] += line[6:] + \"/t\"\n",
    "            elif line[0] == \"J\":\n",
    "                line = line.replace(\"/u\", \"/u \")\n",
    "                lines[counter] += line[8:]\n",
    "                counter += 1\n",
    "                \n",
    "#                 lines.append(\"\")\n",
    "#                 lines[counter] += synonym_replacement(lines[counter-1].split(\"/t\")[0], num_replacements=2) + \"/t\"\n",
    "#                 lines[counter] += lines[counter-1].split(\"/t\")[1]\n",
    "#                 counter += 1\n",
    "                \n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21facffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 20\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0e2a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData():\n",
    "    pairs = readLangs()\n",
    "    pairs = filterPairs(pairs)\n",
    "    for i, pair in enumerate(pairs):\n",
    "        pairs[i] = pair.split(\"/t\")\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aa6f2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "['Why was Donald Trump arrested\\n', \"/u Wiki'Why was Donald Trump arrested'\\n\"]\n"
     ]
    }
   ],
   "source": [
    "pairs = prepareData()\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "480c5efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(tokenizer, encoder, encoding_size, batch_size):\n",
    "    pairs = prepareData()\n",
    "    train_pairs, val_pairs = pairs[:225], pairs[225:]\n",
    "\n",
    "    train_n = len(train_pairs)\n",
    "    val_n = len(val_pairs)\n",
    "    train_input_ids = np.zeros((train_n, MAX_LENGTH, encoding_size), dtype=np.float32)\n",
    "    train_target_ids = np.zeros((train_n, MAX_LENGTH), dtype=np.int32)\n",
    "    train_attention_masks = np.zeros((train_n, MAX_LENGTH), dtype=np.int32)\n",
    "    val_input_ids = np.zeros((val_n, MAX_LENGTH, encoding_size), dtype=np.float32)\n",
    "    val_target_ids = np.zeros((val_n, MAX_LENGTH), dtype=np.int32)\n",
    "    val_attention_masks = np.zeros((val_n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(train_pairs):\n",
    "        inp_encoded = encodeString(inp, tokenizer, encoder)[0][0]\n",
    "        tgt_encoded = tokenizer.encode_plus(tgt,\n",
    "                                            max_length=20,\n",
    "                                            pad_to_max_length=True,\n",
    "                                            return_attention_mask=True,\n",
    "                                            return_tensors=\"pt\")\n",
    "        tgt_tokenized = tgt_encoded['input_ids'][0]\n",
    "#         tgt_masked = tgt_encoded['attention_mask'][0]\n",
    "\n",
    "        targ_in = tgt_tokenized[:-1]\n",
    "        targ_out = tgt_tokenized[1:]\n",
    "\n",
    "        train_input_ids[idx, :len(inp_encoded)] = inp_encoded\n",
    "        train_target_ids[idx, :len(targ_in)] = targ_in\n",
    "        train_attention_masks[idx, :len(targ_out)] = targ_out\n",
    "        \n",
    "    for idx, (inp, tgt) in enumerate(val_pairs):\n",
    "        inp_encoded = encodeString(inp, tokenizer, encoder)[0][0]\n",
    "        tgt_encoded = tokenizer.encode_plus(tgt,\n",
    "                                            max_length=20,\n",
    "                                            pad_to_max_length=True,\n",
    "                                            return_attention_mask=True,\n",
    "                                            return_tensors=\"pt\")\n",
    "        tgt_tokenized = tgt_encoded['input_ids'][0]\n",
    "#         tgt_masked = tgt_encoded['attention_mask'][0]\n",
    "\n",
    "        targ_in = tgt_tokenized[:-1]\n",
    "        targ_out = tgt_tokenized[1:]\n",
    "        \n",
    "        val_input_ids[idx, :len(inp_encoded)] = inp_encoded\n",
    "        val_target_ids[idx, :len(targ_in)] = targ_in\n",
    "        val_attention_masks[idx, :len(targ_out)] = targ_out\n",
    "\n",
    "    train_data = TensorDataset(torch.FloatTensor(train_input_ids).to(device),\n",
    "                               torch.LongTensor(train_target_ids).to(device),\n",
    "                               torch.LongTensor(train_attention_masks).to(device))\n",
    "    val_data = TensorDataset(torch.FloatTensor(val_input_ids).to(device),\n",
    "                             torch.LongTensor(val_target_ids).to(device),\n",
    "                             torch.LongTensor(val_attention_masks).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    val_sampler = RandomSampler(val_data)\n",
    "    val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "    \n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a04182b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathanmon/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = get_dataloader(tokenizer, bert_encoder, last_hidden_states.shape[-1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f5f9d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 1013, 1057, 9617, 8663, 2850, 1005, 2485, 1005,  102,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for data in train_ds:\n",
    "    input_tensor, target_tensor, attention_mask = data\n",
    "    print(target_tensor)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcaba16",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872f4d18",
   "metadata": {},
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4575fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "    depth = depth/2\n",
    "\n",
    "    positions = torch.unsqueeze(torch.arange(length), 1)\n",
    "    depths = torch.unsqueeze(torch.arange(depth), 0)/depth\n",
    "#     positions = torch.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "#     depths = torch.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "    angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "    angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "    pos_encoding = torch.concatenate(\n",
    "      [torch.sin(angle_rads), torch.cos(angle_rads)],\n",
    "      axis=-1) \n",
    "\n",
    "    return pos_encoding.to(device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02f3d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=0)\n",
    "        # The positional encoding is used to introduce sequence to a sentence by causing words near \n",
    "        # eachother to have similar vectors\n",
    "        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "    def compute_mask(self, *args, **kwargs):\n",
    "        return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        length = np.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "        x *= math.sqrt(torch.tensor(self.d_model).type(torch.float32))\n",
    "        x = x + torch.unsqueeze(self.pos_encoding, 0)[:, :length]\n",
    "#         x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "606cd212",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_positional_embedding = PositionalEmbedding(vocab_size=len(tokenizer.get_vocab()),\n",
    "                                                  d_model=768).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42ccc4a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tgt_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1331174/1894896223.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_positional_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tgt_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "print(summary(sample_positional_embedding, tgt_encoded, show_input=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f677df5d",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31b80176",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(nn.Module):\n",
    "    def __init__(self, d_model, **kwargs):\n",
    "        super().__init__()\n",
    "        self.num_heads = kwargs.get('num_heads')\n",
    "        self.mha = nn.MultiheadAttention(**kwargs)\n",
    "        self.layernorm = nn.LayerNorm(d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69e4d8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(BaseAttention):\n",
    "    def forward(self, x, context):\n",
    "        x_ = x.permute(1, 0, 2)\n",
    "        context_ = context.permute(1, 0, 2)\n",
    "        attn_output, attn_scores = self.mha(\n",
    "            query=x_,\n",
    "            key=context_,\n",
    "            value=context_,\n",
    "            need_weights=True)\n",
    "        attn_output = attn_output.permute(1, 0, 2)\n",
    "        attn_scores = attn_scores.permute(1, 0, 2)\n",
    "\n",
    "        # Cache the attention scores for plotting later.\n",
    "        self.last_attn_scores = attn_scores\n",
    "\n",
    "        x =x + attn_output\n",
    "        x = self.layernorm(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "sample_ca = CrossAttention(d_model=256, embed_dim=128, num_heads=2, kdim=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1ead0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(BaseAttention):\n",
    "    def forward(self, x):\n",
    "        x_ = x.permute(1, 0, 2)\n",
    "        attention_mask = nn.Transformer.generate_square_subsequent_mask(x_.shape[0]).to(device)\n",
    "        attention_mask = attention_mask.expand(x_.shape[1]*self.num_heads, -1, -1).to(device)\n",
    "        \n",
    "        attn_output = self.mha(\n",
    "            query=x_,\n",
    "            value=x_,\n",
    "            key=x_,\n",
    "            attn_mask=attention_mask,\n",
    "            is_causal=True)[0]\n",
    "        attn_output = attn_output.permute(1, 0, 2)\n",
    "        x = x + attn_output\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "    \n",
    "sample_csa = CausalSelfAttention(d_model=256, embed_dim=128, \n",
    "                                 num_heads=2, kdim=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1e4092",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61071adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(d_model, dff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dff, d_model),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        ).to(device)\n",
    "        self.layer_norm = nn.LayerNorm(d_model).to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.seq(x)\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "    \n",
    "sample_ffn = FeedForward(28, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eeaacb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                   *,\n",
    "                   d_model,\n",
    "                   num_heads,\n",
    "                   dff,\n",
    "                   dropout_rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.causal_self_attention = CausalSelfAttention(\n",
    "            d_model=d_model,\n",
    "            embed_dim=d_model,\n",
    "            num_heads=num_heads,\n",
    "            kdim=d_model,\n",
    "            dropout=dropout_rate).to(device)\n",
    "        \n",
    "        self.cross_attention = CrossAttention(\n",
    "            d_model=d_model,\n",
    "            embed_dim=d_model,\n",
    "            num_heads=num_heads,\n",
    "            kdim=d_model,\n",
    "            dropout=dropout_rate).to(device)\n",
    "\n",
    "        self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "    def forward(self, x, context):\n",
    "        x = self.causal_self_attention(x=x)\n",
    "        x = self.cross_attention(x=x, context=context)\n",
    "\n",
    "        # Cache the last attention scores for plotting later\n",
    "        self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "        x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92047b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, *, emb_size, num_layers, d_model, num_heads, dff, vocab_size,\n",
    "                   dropout_rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.linear = nn.Linear(emb_size, d_model)\n",
    "        self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
    "                                                 d_model=d_model).to(\"cuda\")\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.dec_layers = [\n",
    "            DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
    "                         dff=dff, dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)]\n",
    "        self.dec_layers = nn.ModuleList(self.dec_layers)\n",
    "\n",
    "        self.last_attn_scores = None\n",
    "\n",
    "    def forward(self, x, context):\n",
    "        # `x` is token-IDs shape (batch, target_seq_len)\n",
    "#         context = self.linear(context)\n",
    "        x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x  = self.dec_layers[i](x, context)\n",
    "\n",
    "        self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "\n",
    "        # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f189ff09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_decoder = Decoder(emb_size=768,\n",
    "                         num_layers=2,\n",
    "                         d_model=768,\n",
    "                         num_heads=8,\n",
    "                         dff=2048,\n",
    "                         vocab_size=len(tokenizer.get_vocab())).to(device)\n",
    "\n",
    "encoded = encodeString(\"hello world\", tokenizer, bert_encoder)[0].to(device)\n",
    "tgt_encoded = tokenizer.encode_plus(\"How's it going robot\",\n",
    "                                    return_tensors=\"pt\")['input_ids'].to(device)\n",
    "decoder_out = sample_decoder(tgt_encoded, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9395495f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------\n",
      "            Layer (type)                   Input Shape         Param #     Tr. Param #\n",
      "=======================================================================================\n",
      "   PositionalEmbedding-1                        [1, 8]      23,440,896      23,440,896\n",
      "               Dropout-2                   [1, 8, 768]               0               0\n",
      "          DecoderLayer-3     [1, 8, 768], [1, 20, 768]       7,877,888       7,877,888\n",
      "          DecoderLayer-4     [1, 8, 768], [1, 20, 768]       7,877,888       7,877,888\n",
      "=======================================================================================\n",
      "Total params: 39,196,672\n",
      "Trainable params: 39,196,672\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(summary(sample_decoder, tgt_encoded, encoded, show_input=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a36fe82",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a6a3648",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, *, emb_size, num_layers, d_model, num_heads, \n",
    "                 dff, vocab_size, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.decoder = Decoder(emb_size=emb_size, num_layers=num_layers, d_model=d_model,\n",
    "                               num_heads=num_heads, dff=dff, vocab_size=vocab_size,\n",
    "                               dropout_rate=dropout_rate)\n",
    "\n",
    "        self.final_layer = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, context, x):\n",
    "        # To use a Keras model with `.fit` you must pass all your inputs in the\n",
    "        # first argument.\n",
    "        \n",
    "        x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
    "\n",
    "        # Final linear layer output.\n",
    "        logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
    "\n",
    "        # Return the final output and the attention weights.\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29449f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 5\n",
    "emb_size = 768\n",
    "d_model = 768\n",
    "dff = 128\n",
    "num_heads = 8\n",
    "dropout_rate = 0.5\n",
    "\n",
    "transformer = Transformer(\n",
    "    emb_size=emb_size,\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    vocab_size=len(tokenizer.get_vocab()),\n",
    "    dropout_rate=dropout_rate).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36d1e286",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------\n",
      "      Layer (type)               Input Shape         Param #     Tr. Param #\n",
      "=============================================================================\n",
      "         Decoder-1     [1, 20], [1, 20, 768]      48,665,728      48,665,728\n",
      "          Linear-2              [1, 20, 768]      23,471,418      23,471,418\n",
      "=============================================================================\n",
      "Total params: 72,137,146\n",
      "Trainable params: 72,137,146\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(summary(transformer, encodeString(\"hello there\", tokenizer, bert_encoder)[0].to(device), \n",
    "                           torch.zeros((1, 20), dtype=torch.int32).to(device), show_input=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaae970",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec36f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(object):\n",
    "    def __init__(self, optimizer, d_model, warmup_steps=4000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.d_model = float(d_model)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "        \n",
    "        self.iters = 0.0\n",
    "\n",
    "    def step(self):\n",
    "        self.iters += 1.0\n",
    "        arg1 = 1 / math.sqrt(self.iters)\n",
    "        arg2 = self.iters * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = 1 / math.sqrt(self.d_model) * min(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c880eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "    #Assuming padding index is 0, adjust if necessary\n",
    "    mask = label != 0\n",
    "\n",
    "    # Calculate CrossEntropyLoss directly without one-hot encoding\n",
    "    loss_object = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    \n",
    "    # Flatten the prediction tensor and the label tensor along the sequence dimension\n",
    "    pred_flat = pred.view(-1, pred.size(-1))\n",
    "    label_flat = label.view(-1)\n",
    "    \n",
    "    # Apply the mask to both the prediction and label tensors\n",
    "    pred_masked = pred_flat[mask.view(-1)]\n",
    "    label_masked = label_flat[mask.view(-1)]\n",
    "    \n",
    "    # Calculate the cross-entropy loss\n",
    "    loss = loss_object(pred_masked, label_masked)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "    pred = torch.argmax(pred, axis=2)\n",
    "    label = label.to(pred.dtype)\n",
    "    match = label == pred\n",
    "\n",
    "    mask = label != 0\n",
    "\n",
    "    match = match & mask\n",
    "\n",
    "    match = match.to(torch.float32)\n",
    "    mask = mask.to(torch.float32)\n",
    "    return torch.sum(match)/torch.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f9b1e3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.6722, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = encodeString(\"hello world\", tokenizer, bert_encoder)[0].to(device)\n",
    "x = torch.tensor([[1, 2, 3, 4]]).to(device)\n",
    "target_tensor_out = torch.tensor([[1, 2, 3, 4]]).to(device)\n",
    "\n",
    "out = transformer(context, x)\n",
    "\n",
    "loss = masked_loss(target_tensor_out, out)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db7cc4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, trasformer, optimizer, scheduler, criterion, train=True):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "#         if torch.randint(low=0, high=5, size=()) == 0:\n",
    "#             rand_batch = torch.randint(len(data[0]), ())\n",
    "#             rand_word = torch.randint(len(data[0][0]), ())\n",
    "#             data[0][rand_batch][rand_word] = OOV_token\n",
    "        input_tensor, target_tensor_in, target_tensor_out = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = transformer(input_tensor, target_tensor_in)\n",
    "        loss = masked_loss(target_tensor_out, logits)\n",
    "        \n",
    "        if train:\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "    \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14cb9672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38685547",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_losses = []\n",
    "\n",
    "def train(train_dataloader, val_dataloader, transformer, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    global plot_train_losses\n",
    "    global d_model\n",
    "    print_train_loss_total = 0  # Reset every print_every\n",
    "    plot_train_loss_total = 0  # Reset every plot_every\n",
    "    \n",
    "    print_val_loss_total = 0  # Reset every print_every\n",
    "\n",
    "    optimizer = optim.Adam(transformer.parameters(), lr=learning_rate, \n",
    "                           betas=(0.9, 0.98), eps=1e-9)\n",
    "    scheduler = CustomSchedule(optimizer, d_model, warmup_steps=6000)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_loss = train_epoch(train_dataloader, transformer, optimizer, scheduler, criterion)\n",
    "        print_train_loss_total += train_loss\n",
    "        plot_train_loss_total += train_loss\n",
    "        \n",
    "        # Evaluate validation dataloader\n",
    "        val_loss = train_epoch(val_dataloader, transformer, optimizer, scheduler, criterion, train=False)\n",
    "        print_val_loss_total += val_loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_train_loss_avg = print_train_loss_total / print_every\n",
    "            print_train_loss_total = 0\n",
    "            print_val_loss_avg = print_val_loss_total / print_every\n",
    "            print_val_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_train_loss_avg, print_val_loss_avg\n",
    "                                             ))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_train_loss_avg = plot_train_loss_total / plot_every\n",
    "            plot_train_losses.append(plot_train_loss_avg)\n",
    "            plot_train_loss_total = 0\n",
    "\n",
    "    showPlot(plot_train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2006fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a0f5570",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "0m 1s (- 0m 46s) (5 2%) 2.6297 4.5404\n",
      "0m 2s (- 0m 45s) (10 5%) 1.5081 3.3736\n",
      "0m 3s (- 0m 43s) (15 7%) 0.6422 2.8761\n",
      "0m 4s (- 0m 42s) (20 10%) 0.3646 2.6548\n",
      "0m 5s (- 0m 41s) (25 12%) 0.2045 2.6262\n",
      "0m 6s (- 0m 39s) (30 15%) 0.1800 2.5209\n",
      "0m 8s (- 0m 38s) (35 17%) 0.1094 2.6591\n",
      "0m 9s (- 0m 37s) (40 20%) 0.0976 2.3830\n",
      "0m 10s (- 0m 36s) (45 22%) 0.0721 2.7252\n",
      "0m 11s (- 0m 35s) (50 25%) 0.0643 2.6067\n",
      "0m 12s (- 0m 34s) (55 27%) 0.0584 2.4533\n",
      "0m 14s (- 0m 33s) (60 30%) 0.0561 2.9603\n",
      "0m 15s (- 0m 31s) (65 32%) 0.0591 2.7089\n",
      "0m 16s (- 0m 30s) (70 35%) 0.0522 2.7283\n",
      "0m 17s (- 0m 29s) (75 37%) 0.0817 2.5434\n",
      "0m 19s (- 0m 28s) (80 40%) 0.0461 2.4571\n",
      "0m 20s (- 0m 27s) (85 42%) 0.0453 2.7756\n",
      "0m 21s (- 0m 26s) (90 45%) 0.0562 2.6533\n",
      "0m 23s (- 0m 25s) (95 47%) 0.0416 2.8827\n",
      "0m 24s (- 0m 24s) (100 50%) 0.0386 2.7423\n",
      "0m 25s (- 0m 23s) (105 52%) 0.0579 2.7289\n",
      "0m 27s (- 0m 22s) (110 55%) 0.0591 2.6370\n",
      "0m 28s (- 0m 21s) (115 57%) 0.0681 2.7780\n",
      "0m 29s (- 0m 19s) (120 60%) 0.0489 2.6655\n",
      "0m 31s (- 0m 18s) (125 62%) 0.0312 2.6471\n",
      "0m 32s (- 0m 17s) (130 65%) 0.0286 2.7678\n",
      "0m 33s (- 0m 16s) (135 67%) 0.0292 2.8928\n",
      "0m 35s (- 0m 15s) (140 70%) 0.0371 2.6763\n",
      "0m 36s (- 0m 13s) (145 72%) 0.0406 2.8459\n",
      "0m 37s (- 0m 12s) (150 75%) 0.0499 2.6804\n",
      "0m 39s (- 0m 11s) (155 77%) 0.0276 2.6090\n",
      "0m 40s (- 0m 10s) (160 80%) 0.0238 2.8173\n",
      "0m 41s (- 0m 8s) (165 82%) 0.0219 3.0254\n",
      "0m 43s (- 0m 7s) (170 85%) 0.0231 3.0004\n",
      "0m 44s (- 0m 6s) (175 87%) 0.0240 2.9780\n",
      "0m 46s (- 0m 5s) (180 90%) 0.0247 2.7094\n",
      "0m 47s (- 0m 3s) (185 92%) 0.0248 2.7447\n",
      "0m 48s (- 0m 2s) (190 95%) 0.0205 3.1022\n",
      "0m 50s (- 0m 1s) (195 97%) 0.0442 2.8725\n",
      "0m 51s (- 0m 0s) (200 100%) 0.0265 3.1236\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataloader, val_dataloader = get_dataloader(tokenizer, bert_encoder, 768, batch_size)\n",
    "\n",
    "train(train_dataloader, val_dataloader, transformer, 200, learning_rate=1e-3, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "634ed8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  1013,  1057, 15536,  3211,  1005,  2073,  2001,  1996,  2942,\n",
      "          2162,  1005,   102,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1013,  1057, 15536,  3211,  1005,  2073,  2001,  1996,  2942,  2162,\n",
      "          1005,   102,     0,     0,     0,     0,     0,     0]],\n",
      "       device='cuda:0')\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for input, target_in, target_out in train_dataloader:\n",
    "    index = -2\n",
    "    input = torch.unsqueeze(input[0], 0)\n",
    "    target_in = torch.unsqueeze(target_in[0][:index], 0)\n",
    "    target_out = torch.unsqueeze(target_out[0][:index], 0)\n",
    "    print(target_in)\n",
    "    print(target_out)\n",
    "    out = transformer(input, target_in)\n",
    "    loss = masked_loss(target_out, out)\n",
    "    print(loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a95f2c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentenceFromIndexes(encoded):\n",
    "    words = []\n",
    "    for word in encoded:\n",
    "        words.append(list(tokenizer.get_vocab().keys())[word])\n",
    "        \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cce97819",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot():\n",
    "    def __init__(self, transformer):\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def __call__(self, sentence):\n",
    "#         if len(sentence.shape) == 0:\n",
    "#             sentence = torch.unsqueeze(sentence, 1)\n",
    "\n",
    "        sentence, attention_mask = encodeString(sentence, tokenizer, bert_encoder)\n",
    "        encoder_input = sentence\n",
    "\n",
    "        output_array = torch.tensor([[SOS_token]])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(MAX_LENGTH):\n",
    "                output = torch.unsqueeze(torch.flatten(output_array), 0)\n",
    "                predictions = self.transformer(encoder_input.to(device),\n",
    "                                                output.to(device))\n",
    "                predictions = predictions[:, -1:, :]\n",
    "                \n",
    "                predicted_id = torch.argmax(predictions, -1)\n",
    "                \n",
    "                output_array = torch.cat((output_array.to(device),\n",
    "                                          torch.unsqueeze(predicted_id[0], 0)), 0)\n",
    "                \n",
    "                if predicted_id[0] == torch.tensor([EOS_token]).to(device):\n",
    "                    break\n",
    "\n",
    "        output = torch.unsqueeze(torch.flatten(output_array), 0)\n",
    "        \n",
    "        tokens = sentenceFromIndexes(output[0].tolist())\n",
    "        text = ' '.join(tokens)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.transformer(encoder_input.to(device), \n",
    "                              output[:,:-1].to(device))\n",
    "            attention_weights = self.transformer.decoder.last_attn_scores\n",
    "\n",
    "        return text, attention_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f99bac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = Chatbot(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3c65cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_translation(sentence, tokens):\n",
    "    print(f'{\"Input:\":15s}: {sentence}')\n",
    "    print(f'\\n{\"Prediction\":15s}: {tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9a0e3adf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:         : What's the temperature\n",
      "\n",
      "Prediction     : [CLS] today is / u date [SEP]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"What's the temperature\"\n",
    "\n",
    "translated_text, attention_weights = chatbot(sentence)\n",
    "print_translation(sentence, translated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
