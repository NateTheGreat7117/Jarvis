{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9aa929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ccf0d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b27e58fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z'/!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"'\", \" '\", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd2d053c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"yes sir /uanaconda 'close '\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizeString(\"Yes sir. /uanaconda'close' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42d5e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    lines = []\n",
    "    counter = 0\n",
    "\n",
    "    with open(\"/media/nathanmon/389E28739E282BB6/Users/Natha/Datasets/MyJarvisConversation/conversation.txt\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            if line[0] == \"U\":\n",
    "                lines.append(\"\")\n",
    "                lines[counter] += line[6:]\n",
    "            elif line[0] == \"J\":\n",
    "                lines[counter] += line[8:]\n",
    "                counter += 1\n",
    "\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\n')[:2]] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fac40603",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 20\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2c15d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 241 sentence pairs\n",
      "Trimmed to 241 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "User:  286\n",
      "Jarvis:  269\n",
      "['thanks', 'sure']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(\"User: \", input_lang.n_words)\n",
    "    print(\"Jarvis: \",output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('usr', 'jar', False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bdb1fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5fbee232",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3474c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc0db904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in normalizeString(sentence).split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData('eng', 'fra', False)\n",
    "    train_pairs, val_pairs = pairs[:225], pairs[225:]\n",
    "\n",
    "    train_n = len(train_pairs)\n",
    "    val_n = len(val_pairs)\n",
    "    train_input_ids = np.zeros((train_n, MAX_LENGTH), dtype=np.int32)\n",
    "    train_target_ids = np.zeros((train_n, MAX_LENGTH), dtype=np.int32)\n",
    "    val_input_ids = np.zeros((val_n, MAX_LENGTH), dtype=np.int32)\n",
    "    val_target_ids = np.zeros((val_n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(train_pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        train_input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        train_target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "        \n",
    "    for idx, (inp, tgt) in enumerate(val_pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        val_input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        val_target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(train_input_ids).to(device),\n",
    "                               torch.LongTensor(train_target_ids).to(device))\n",
    "    val_data = TensorDataset(torch.LongTensor(val_input_ids).to(device),\n",
    "                               torch.LongTensor(val_target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    val_sampler = RandomSampler(val_data)\n",
    "    val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "    \n",
    "    return input_lang, output_lang, train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b36b0b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion, train=True):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        if train:\n",
    "            loss.backward()\n",
    "\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e050fdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa8518ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, val_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_train_losses = []\n",
    "    print_train_loss_total = 0  # Reset every print_every\n",
    "    plot_train_loss_total = 0  # Reset every plot_every\n",
    "    \n",
    "    print_val_loss_total = 0  # Reset every print_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_train_loss_total += train_loss\n",
    "        plot_train_loss_total += train_loss\n",
    "        \n",
    "        # Evaluate validation dataloader\n",
    "        val_loss = train_epoch(val_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, train=False)\n",
    "        print_val_loss_total += val_loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_train_loss_avg = print_train_loss_total / print_every\n",
    "            print_train_loss_total = 0\n",
    "            print_val_loss_avg = print_val_loss_total / print_every\n",
    "            print_val_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_train_loss_avg, print_val_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_train_loss_avg = plot_train_loss_total / plot_every\n",
    "            plot_train_losses.append(plot_train_loss_avg)\n",
    "            plot_train_loss_total = 0\n",
    "\n",
    "    showPlot(plot_train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a9bd572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dee0e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "acc3486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1118f2a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 241 sentence pairs\n",
      "Trimmed to 241 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "User:  286\n",
      "Jarvis:  269\n",
      "0m 1s (- 2m 28s) (5 1%) 1.0180 0.6901\n",
      "0m 2s (- 2m 24s) (10 2%) 0.4096 0.6341\n",
      "0m 4s (- 2m 22s) (15 3%) 0.1995 0.6422\n",
      "0m 5s (- 2m 20s) (20 4%) 0.1024 0.6630\n",
      "0m 7s (- 2m 19s) (25 5%) 0.0544 0.6693\n",
      "0m 8s (- 2m 17s) (30 6%) 0.0302 0.6849\n",
      "0m 10s (- 2m 15s) (35 7%) 0.0155 0.6961\n",
      "0m 11s (- 2m 14s) (40 8%) 0.0115 0.7030\n",
      "0m 13s (- 2m 12s) (45 9%) 0.0102 0.7097\n",
      "0m 14s (- 2m 9s) (50 10%) 0.0071 0.7243\n",
      "0m 15s (- 2m 7s) (55 11%) 0.0056 0.7166\n",
      "0m 17s (- 2m 5s) (60 12%) 0.0050 0.7363\n",
      "0m 18s (- 2m 3s) (65 13%) 0.0045 0.7424\n",
      "0m 19s (- 2m 1s) (70 14%) 0.0044 0.7351\n",
      "0m 21s (- 1m 59s) (75 15%) 0.0041 0.7547\n",
      "0m 22s (- 1m 57s) (80 16%) 0.0036 0.7619\n",
      "0m 23s (- 1m 56s) (85 17%) 0.0037 0.7514\n",
      "0m 25s (- 1m 54s) (90 18%) 0.0072 0.7610\n",
      "0m 26s (- 1m 52s) (95 19%) 0.0041 0.7610\n",
      "0m 27s (- 1m 51s) (100 20%) 0.0037 0.7755\n",
      "0m 29s (- 1m 49s) (105 21%) 0.0036 0.7774\n",
      "0m 30s (- 1m 48s) (110 22%) 0.0052 0.7714\n",
      "0m 31s (- 1m 46s) (115 23%) 0.0035 0.7817\n",
      "0m 33s (- 1m 45s) (120 24%) 0.0032 0.7694\n",
      "0m 34s (- 1m 43s) (125 25%) 0.0032 0.7933\n",
      "0m 35s (- 1m 42s) (130 26%) 0.0029 0.7746\n",
      "0m 37s (- 1m 40s) (135 27%) 0.0030 0.7902\n",
      "0m 38s (- 1m 39s) (140 28%) 0.0030 0.8163\n",
      "0m 39s (- 1m 37s) (145 28%) 0.0044 0.8049\n",
      "0m 41s (- 1m 36s) (150 30%) 0.0031 0.8016\n",
      "0m 42s (- 1m 34s) (155 31%) 0.0030 0.7906\n",
      "0m 43s (- 1m 33s) (160 32%) 0.0038 0.8020\n",
      "0m 45s (- 1m 31s) (165 33%) 0.0052 0.8070\n",
      "0m 46s (- 1m 30s) (170 34%) 0.0030 0.8038\n",
      "0m 47s (- 1m 28s) (175 35%) 0.0030 0.8050\n",
      "0m 49s (- 1m 27s) (180 36%) 0.0058 0.8153\n",
      "0m 50s (- 1m 26s) (185 37%) 0.0196 0.7805\n",
      "0m 51s (- 1m 24s) (190 38%) 0.0250 0.7400\n",
      "0m 53s (- 1m 23s) (195 39%) 0.0099 0.7777\n",
      "0m 54s (- 1m 21s) (200 40%) 0.0071 0.8026\n",
      "0m 55s (- 1m 20s) (205 41%) 0.0039 0.8199\n",
      "0m 57s (- 1m 19s) (210 42%) 0.0094 0.8234\n",
      "0m 58s (- 1m 17s) (215 43%) 0.0046 0.7918\n",
      "1m 0s (- 1m 16s) (220 44%) 0.0032 0.8121\n",
      "1m 1s (- 1m 15s) (225 45%) 0.0028 0.7986\n",
      "1m 2s (- 1m 13s) (230 46%) 0.0027 0.8161\n",
      "1m 4s (- 1m 12s) (235 47%) 0.0028 0.8013\n",
      "1m 5s (- 1m 11s) (240 48%) 0.0027 0.8266\n",
      "1m 7s (- 1m 9s) (245 49%) 0.0027 0.8267\n",
      "1m 8s (- 1m 8s) (250 50%) 0.0026 0.8181\n",
      "1m 10s (- 1m 7s) (255 51%) 0.0028 0.8345\n",
      "1m 11s (- 1m 6s) (260 52%) 0.0029 0.8127\n",
      "1m 12s (- 1m 4s) (265 53%) 0.0027 0.8226\n",
      "1m 14s (- 1m 3s) (270 54%) 0.0027 0.8380\n",
      "1m 15s (- 1m 2s) (275 55%) 0.0024 0.8387\n",
      "1m 17s (- 1m 0s) (280 56%) 0.0026 0.8543\n",
      "1m 18s (- 0m 59s) (285 56%) 0.0026 0.8461\n",
      "1m 19s (- 0m 57s) (290 57%) 0.0026 0.8426\n",
      "1m 21s (- 0m 56s) (295 59%) 0.0034 0.8448\n",
      "1m 22s (- 0m 55s) (300 60%) 0.0050 0.8461\n",
      "1m 24s (- 0m 53s) (305 61%) 0.0028 0.8648\n",
      "1m 25s (- 0m 52s) (310 62%) 0.0027 0.8640\n",
      "1m 26s (- 0m 51s) (315 63%) 0.0027 0.8728\n",
      "1m 28s (- 0m 49s) (320 64%) 0.0025 0.8474\n",
      "1m 29s (- 0m 48s) (325 65%) 0.0027 0.8495\n",
      "1m 31s (- 0m 46s) (330 66%) 0.0025 0.8775\n",
      "1m 32s (- 0m 45s) (335 67%) 0.0028 0.8752\n",
      "1m 33s (- 0m 44s) (340 68%) 0.0024 0.8638\n",
      "1m 35s (- 0m 42s) (345 69%) 0.0025 0.8603\n",
      "1m 36s (- 0m 41s) (350 70%) 0.0025 0.8697\n",
      "1m 37s (- 0m 40s) (355 71%) 0.0027 0.8772\n",
      "1m 39s (- 0m 38s) (360 72%) 0.0065 0.8590\n",
      "1m 40s (- 0m 37s) (365 73%) 0.0044 0.8245\n",
      "1m 42s (- 0m 35s) (370 74%) 0.0029 0.8299\n",
      "1m 43s (- 0m 34s) (375 75%) 0.0025 0.8254\n",
      "1m 45s (- 0m 33s) (380 76%) 0.0025 0.8337\n",
      "1m 46s (- 0m 31s) (385 77%) 0.0026 0.8356\n",
      "1m 47s (- 0m 30s) (390 78%) 0.0056 0.8294\n",
      "1m 49s (- 0m 29s) (395 79%) 0.0056 0.7951\n",
      "1m 50s (- 0m 27s) (400 80%) 0.0032 0.7897\n",
      "1m 52s (- 0m 26s) (405 81%) 0.0038 0.8016\n",
      "1m 53s (- 0m 24s) (410 82%) 0.0050 0.8183\n",
      "1m 54s (- 0m 23s) (415 83%) 0.0031 0.8037\n",
      "1m 56s (- 0m 22s) (420 84%) 0.0026 0.8048\n",
      "1m 57s (- 0m 20s) (425 85%) 0.0024 0.8340\n",
      "1m 58s (- 0m 19s) (430 86%) 0.0046 0.8460\n",
      "2m 0s (- 0m 17s) (435 87%) 0.0036 0.8148\n",
      "2m 1s (- 0m 16s) (440 88%) 0.0025 0.8123\n",
      "2m 3s (- 0m 15s) (445 89%) 0.0048 0.8165\n",
      "2m 4s (- 0m 13s) (450 90%) 0.0248 0.8021\n",
      "2m 5s (- 0m 12s) (455 91%) 0.0244 0.8960\n",
      "2m 7s (- 0m 11s) (460 92%) 0.0095 0.8740\n",
      "2m 8s (- 0m 9s) (465 93%) 0.0062 0.8821\n",
      "2m 9s (- 0m 8s) (470 94%) 0.0028 0.9208\n",
      "2m 11s (- 0m 6s) (475 95%) 0.0027 0.9081\n",
      "2m 12s (- 0m 5s) (480 96%) 0.0026 0.9020\n",
      "2m 14s (- 0m 4s) (485 97%) 0.0025 0.8889\n",
      "2m 15s (- 0m 2s) (490 98%) 0.0025 0.9227\n",
      "2m 16s (- 0m 1s) (495 99%) 0.0027 0.8924\n",
      "2m 18s (- 0m 0s) (500 100%) 0.0025 0.9043\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 512\n",
    "batch_size = 16\n",
    "dropout_p = 0.5\n",
    "\n",
    "input_lang, output_lang, train_dataloader, val_dataloader = get_dataloader(batch_size)\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, dropout_p=dropout_p).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=dropout_p).to(device)\n",
    "\n",
    "train(train_dataloader, val_dataloader, encoder, decoder, 500, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5229a30",
   "metadata": {},
   "source": [
    "# Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a1008c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_place = {\"zero\": 0, \"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4, \n",
    "              \"five\": 5, \"six\": 6, \"seven\": 7, \"eight\": 8, \"nine\": 9,\n",
    "              \"ten\": 10, \"eleven\": 11, \"twelve\": 12, \"thirteen\": 13,\n",
    "              \"fourteen\": 14, \"fifteen\": 15, \"sixteen\": 16, \n",
    "              \"seventeen\": 17, \"eighteen\": 18, \"nineteen\": 19}\n",
    "\n",
    "tens_place = {\"twenty\": 20, \"thirty\": 30, \"forty\": 40, \"fifty\": 50,\n",
    "              \"sixty\": 60, \"seventy\": 70, \"eighty\": 80, \"ninety\": 90}\n",
    "\n",
    "hundreds_place = {\"hundred\": 10**2, \"thousand\": 10**3, \"million\": 10**6, \"billion\": 10**9,\n",
    "                  \"trillion\": 10**12, \"quadrillion\": 10**15, \"quintillion\": 10**18}\n",
    "\n",
    "# Convert word form to numbers\n",
    "# Works for numbers up to the quintillions\n",
    "# Also works for dates like nineteen sixty three of twenty twenty four\n",
    "def word2num(word):\n",
    "    digits = word.split()\n",
    "    num = 0\n",
    "    \n",
    "    has_ones = False\n",
    "    has_tens = False\n",
    "    tens = 0\n",
    "    hundreds = 0\n",
    "    for i in range(len(digits)):\n",
    "        digit = digits[i]\n",
    "        \n",
    "        if digit in ones_place:\n",
    "            # In a real number, there would never be a ones place or tens place next to another ones place\n",
    "            # For example, there is never nine nineteen or four ninety\n",
    "            # However, this is seen in a year such as nineteen forty one\n",
    "            if (has_tens and ones_place[digit] >= 10) or has_ones:\n",
    "                num *= 100\n",
    "                \n",
    "            num += ones_place[digit]\n",
    "            # Store the tens place and hundreds place in case there is a thousand or million in front of them\n",
    "            tens += ones_place[digit]\n",
    "            hundreds += ones_place[digit]\n",
    "            # Store boolean values to see if there has been a tens place or ones place\n",
    "            has_ones = True\n",
    "            has_tens = False\n",
    "    \n",
    "        elif digit in tens_place:\n",
    "            if has_ones or has_tens:\n",
    "                # If someone enters a year(eighteen twelve works different than one thousand eight hundred twelve)\n",
    "                num *= 100\n",
    "                has_tens = False\n",
    "            else:\n",
    "                has_tens = True\n",
    "            \n",
    "            num += tens_place[digit]\n",
    "            tens += tens_place[digit]\n",
    "            hundreds += tens_place[digit]\n",
    "            has_ones = False\n",
    "            \n",
    "        elif digit in hundreds_place:\n",
    "            if digit != \"hundred\" and hundreds:\n",
    "                num += hundreds * hundreds_place[digit] - hundreds\n",
    "                hundreds = 0\n",
    "                tens = 0\n",
    "            else:\n",
    "                num += tens * hundreds_place[digit] - tens\n",
    "                hundreds = tens * hundreds_place[digit]\n",
    "                tens = 0\n",
    "            has_ones = False\n",
    "            has_tens = False\n",
    "        \n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8ca5d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\"\n",
    "}\n",
    "def weather(city, wob):\n",
    "    res = requests.get(\n",
    "        f'https://www.google.com/search?q={city}+weather&rlz=1C1VDKB_enUS1016US1016&oq={city}&aqs=chrome.0.69i59j69i57j69i59l2j0i271l2j69i61l2.905j0j7&sourceid=chrome&ie=UTF-8',\n",
    "        headers=headers\n",
    "    )\n",
    "    soup = bs4(res.text, 'html.parser')\n",
    "    return soup.select(f\"#wob_{wob}\")[0].getText().strip()\n",
    "\n",
    "def volume(vol):\n",
    "    devices = AudioUtilities.GetSpeakers()\n",
    "    interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "    volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "    volume.SetMasterVolumeLevelScalar(word2num(vol)/100, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55642dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak: volume sixteen\n",
      "Response:  later graphical graphical /ufile out be be dinner out my teeth fifth dinner dinner dinner dinner dinner dinner dinner\n",
      "Filtered:  later graphical graphical /ufile out be be dinner out my teeth fifth dinner dinner dinner dinner dinner dinner dinner\n",
      "Speak: sleep\n",
      "Response:  SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS\n",
      "Filtered:  SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS\n",
      "Speak: what's the date jarvis\n",
      "Response:  SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS\n",
      "Filtered:  SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS\n",
      "Speak: what is the date\n",
      "Response:  \n",
      "Filtered:  \n",
      "Speak: what is the date jarvis\n",
      "Response:  \n",
      "Filtered:  \n",
      "Speak: what's the temperature\n",
      "Response:  SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS\n",
      "Filtered:  SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_482728/1338706865.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mchat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Speak: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m             )\n\u001b[0;32m-> 1044\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1045\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    chat = input(\"Speak: \")\n",
    "    output = evaluate(encoder, decoder, chat, input_lang, output_lang)\n",
    "    response = ' '.join(output[0][:-1])\n",
    "    \n",
    "    print(\"Response: \", response)\n",
    "    # Get the date\n",
    "    if \"/udate\" in response:\n",
    "        response = response.replace(\"/udate\", datetime.date.today().strftime(\"%B %d, %Y\"))\n",
    "    # Get the time\n",
    "    if \"/utime\" in response:\n",
    "        response = response.replace(\"/utime\", datetime.datetime.now().strftime(\"%I:%M:%S\"))\n",
    "    # Get the temperature\n",
    "    if \"/utemp\" in response:\n",
    "        response = response.replace(\"/utemp\", weather(\"boston\", \"tm\"))\n",
    "    # Get the humidity\n",
    "    if \"/uhumidity\" in response:\n",
    "        response = response.replace(\"/uhumidity\", weather(\"boston\", \"hm\"))\n",
    "    # Get the wind speed\n",
    "    if \"/uwind\" in response:\n",
    "        response = response.replace(\"/uwind\", weather(\"boston\", \"ws\"))\n",
    "    # Get the amount of precipitation\n",
    "    if \"/uprecipitation\" in response:\n",
    "        response = response.replace(\"/uprecipitation\", weather(\"boston\", \"pp\"))\n",
    "    if \"/uvolume\" in response:\n",
    "        after = response.split(\"/uvolume\")[-1]\n",
    "        vol = after.split(\"'\")[1]\n",
    "        #response = response.replace(\"/uvolume\"+\"'\"+vol+\"'\", \"\")\n",
    "        volume(vol)\n",
    "    if \"/usleep\" in response:\n",
    "        response = response.replace(\"/usleep\", \"\")\n",
    "        print(response)\n",
    "        break\n",
    "    if \"/unewtab\" in response:\n",
    "        response = response.replace(\"/unewtab\", \"\")\n",
    "        pyautogui.hotkey('ctrl', 't')\n",
    "    if \"/uclosetab\" in response:\n",
    "        response = response.replace(\"/uclosetab\", \"\")\n",
    "        pyautogui.hotkey('ctrl', 'w')\n",
    "    if \"/uswitchtab\" in response:\n",
    "        after = response.split(\"/uvolume\")[-1]\n",
    "        new = after.split(\"'\")[1]\n",
    "        response = response.replace(\"/uswitchtab\"+\"'\"+new+\"'\", \"\")\n",
    "        pyautogui.hotkey('ctrl', str(word2num(new)))\n",
    "    \n",
    "    print(\"Filtered: \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c940bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36e1a19a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goodbye sir usleep'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(response[:-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
